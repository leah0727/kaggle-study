{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMZRjlKGNcF7zZU1hwHdalW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8KNc-I-ihsR","executionInfo":{"status":"ok","timestamp":1727089287512,"user_tz":-540,"elapsed":18477,"user":{"displayName":"Yeongeun Ra","userId":"17702977685342597921"}},"outputId":"646624b5-94cf-4bd0-ef61-dfc6bd08bc45"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading , 80247571 bytes compressed\n","[==================================================] 80247571 bytes downloaded\n","Downloaded and uncompressed: \n","Data source import complete.\n"]}],"source":["\n","# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n","# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n","# THEN FEEL FREE TO DELETE THIS CELL.\n","# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n","# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n","# NOTEBOOK.\n","\n","import os\n","import sys\n","from tempfile import NamedTemporaryFile\n","from urllib.request import urlopen\n","from urllib.parse import unquote, urlparse\n","from urllib.error import HTTPError\n","from zipfile import ZipFile\n","import tarfile\n","import shutil\n","\n","CHUNK_SIZE = 40960\n","DATA_SOURCE_MAPPING = ':https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-competitions-data%2Fkaggle-v2%2F7082%2F874852%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240923%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240923T105900Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D6477049566f97a61b0e2296a7ab150dbd5d6fce54141cb6a735a35e244cc2a141568e74e5bf94cfb867b50e34197eb6ba8ae61ec22d7a6bbaa6e0de4ae5aca0cd4b572cd2efd648cb3ba5dad55889f80d09005de6751c3d16a9bcfc5d2a0bbc19c52e220657dcadacb4ad541bcd189a396b4e6187a179a3c01a1c063c148a0a43186f5db2798e86bed98634eb1889e510c92c1a90ae2b9ceea669b92908c401fde1ceeb90f0cd0b8ba276f2fa730a538bd8692ef7079750bda7777330c7712261dc0374c140bf74398445504579c45ae8061cb9e5d4ade49e95c9ef05ce8be3d43f31e3e3d2308140c37bb79c9de19643ffec222f6ece0b95de303177f0f1f12'\n","\n","KAGGLE_INPUT_PATH='/kaggle/input'\n","KAGGLE_WORKING_PATH='/kaggle/working'\n","KAGGLE_SYMLINK='kaggle'\n","\n","!umount /kaggle/input/ 2> /dev/null\n","shutil.rmtree('/kaggle/input', ignore_errors=True)\n","os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n","os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n","\n","try:\n","  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n","except FileExistsError:\n","  pass\n","try:\n","  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n","except FileExistsError:\n","  pass\n","\n","for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n","    directory, download_url_encoded = data_source_mapping.split(':')\n","    download_url = unquote(download_url_encoded)\n","    filename = urlparse(download_url).path\n","    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n","    try:\n","        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n","            total_length = fileres.headers['content-length']\n","            print(f'Downloading {directory}, {total_length} bytes compressed')\n","            dl = 0\n","            data = fileres.read(CHUNK_SIZE)\n","            while len(data) > 0:\n","                dl += len(data)\n","                tfile.write(data)\n","                done = int(50 * dl / int(total_length))\n","                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n","                sys.stdout.flush()\n","                data = fileres.read(CHUNK_SIZE)\n","            if filename.endswith('.zip'):\n","              with ZipFile(tfile) as zfile:\n","                zfile.extractall(destination_path)\n","            else:\n","              with tarfile.open(tfile.name) as tarfile:\n","                tarfile.extractall(destination_path)\n","            print(f'\\nDownloaded and uncompressed: {directory}')\n","    except HTTPError as e:\n","        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n","        continue\n","    except OSError as e:\n","        print(f'Failed to load {download_url} to path {destination_path}')\n","        continue\n","\n","print('Data source import complete.')\n"]},{"cell_type":"code","source":["MAX_ROUNDS = 400\n","OPTIMIZE_ROUNDS = False\n","LEARNING_RATE = 0.07\n","EARLY_STOPPING_ROUNDS = 50\n","# Note: I set EARLY_STOPPING_ROUNDS high so that (when OPTIMIZE_ROUNDS is set)\n","#       I will get lots of information to make my own judgment.  You should probably\n","#       reduce EARLY_STOPPING_ROUNDS if you want to do actual early stopping."],"metadata":{"id":"z3i-_AE8iqvD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from xgboost import XGBClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from sklearn.preprocessing import LabelEncoder\n","from numba import jit\n","import time\n","import gc"],"metadata":{"id":"4tphfFobiuJ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Compute gini\n","\n","# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n","@jit\n","def eval_gini(y_true, y_prob):\n","    y_true = np.asarray(y_true)\n","    y_true = y_true[np.argsort(y_prob)]\n","    ntrue = 0\n","    gini = 0\n","    delta = 0\n","    n = len(y_true)\n","    for i in range(n-1, -1, -1):\n","        y_i = y_true[i]\n","        ntrue += y_i\n","        gini += y_i * delta\n","        delta += 1 - y_i\n","    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n","    return gini"],"metadata":{"id":"W16pOTIWi6Fi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from numba import jit\n","import numpy as np\n","\n","@jit\n","def eval_gini(y_true, y_prob):\n","    # Pandas Series를 NumPy 배열로 변환\n","    y_true = np.asarray(y_true)\n","    y_prob = np.asarray(y_prob)\n","\n","    # 예측 확률에 따라 실제 값을 정렬\n","    y_true = y_true[np.argsort(y_prob)]\n","\n","    ntrue = 0\n","    gini = 0\n","    delta = 0\n","    n = len(y_true)\n","\n","    # Gini 계산\n","    for i in range(n-1, -1, -1):\n","        y_i = y_true[i]\n","        ntrue += y_i\n","        gini += y_i * delta\n","        delta += 1 - y_i\n","\n","    gini = 1 - 2 * gini / (ntrue * (n - ntrue))\n","    return gini\n"],"metadata":{"id":"0bJTmxyqpSzJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- Gini 계수를 계산하는 함수로, @jit 데코레이터를 사용해 Numba를 통해 성능을 최적화한 것입니다. Gini 계수는 주로 불균형 데이터에서 모델의 성능을 평가할 때 사용되는 지표로, 특히 이진 분류에서 자주 사용됩니다. 이 코드에서는 Gini 계수를 직접 구현하여, 모델의 예측 성능을 평가할 수 있습니다.\n","\n","- Gini 계수는 1에 가까울수록 모델의 성능이 좋음을 나타냅니다. 0에 가까울수록 성능이 낮으며, 음수일 경우에는 모델이 성능을 제대로 발휘하지 못하는 경우를 나타냅니다.\n","\n","- Gini 계수의 의미:\n","- Gini 계수는 불균형한 데이터에 대한 모델 성능 평가 지표로, ROC 곡선의 AUC 값과 밀접한 관련이 있습니다.\n","- 정상적인 Gini 계수는 0 ~ 1 범위에서 측정되며, 1에 가까울수록 모델이 타겟 값을 정확하게 예측할 수 있음을 의미합니다.\n","- 0은 완전히 무작위 예측을 의미하며, 음수 값은 예측이 잘못되었다는 신호일 수 있습니다."],"metadata":{"id":"z-JY2YJ6j9vZ"}},{"cell_type":"markdown","source":[],"metadata":{"id":"7gi7Erlvkj8G"}},{"cell_type":"markdown","source":["특히 Gini 계수 계산, 타겟 인코딩(target encoding), 그리고 노이즈 추가와 관련된 작업을 수행하는 함수들입니다.\n","\n"],"metadata":{"id":"aRJXXl02kjtx"}},{"cell_type":"markdown","source":["- gini_xgb: XGBoost에서 Gini 계수를 커스텀 평가지표로 사용할 수 있도록 정의한 함수.\n","- add_noise: 타겟 인코딩 후 노이즈를 추가하여 과적합을 방지하는 함수.\n","- target_encode: 범주형 변수에 대해 타겟 인코딩을 적용하는 함수로, 평활화와 노이즈 추가를 통해 성능을 최적화함."],"metadata":{"id":"XTopoDHMlLg0"}},{"cell_type":"markdown","source":["**타겟 인코딩(Target Encoding)**은 이러한 범주형 변수를 수치형 변수로 변환하는 인코딩 방식 중 하나입니다. 타겟 인코딩은 각 범주(category)를 타겟 변수의 평균 값으로 변환하는 방식으로, 타겟 변수와의 관계를 더 잘 반영하는 수치형 데이터를 생성합니다.\n","\n","예시:\n","타겟 변수: 고객이 보험금을 청구했는지 여부 (0 또는 1)\n","범주형 변수: 고객이 소유한 차량 종류 (A, B, C)\n","타겟 인코딩을 사용하면 차량 종류 A, B, C가 각각의 차량에 대해 타겟 변수의 평균값으로 변환됩니다. 예를 들어:\n","\n","차량 A: 0.25 (차량 A를 가진 고객 중 25%가 보험금을 청구했다는 의미)\n","차량 B: 0.5 (차량 B를 가진 고객 중 50%가 청구)\n","차량 C: 0.1 (차량 C를 가진 고객 중 10%가 청구)\n","\n","- 타겟 인코딩을 사용하는 이유:\n","범주형 변수를 다루는 방법에는 여러 가지가 있지만, 타겟 인코딩은 특히 다음과 같은 경우에 유용합니다:\n","- 범주가 많은 경우: 원-핫 인코딩(one-hot encoding)을 사용할 경우 고차원 문제가 발생할 수 있습니다. 타겟 인코딩은 이러한 문제를 해결할 수 있습니다.\n","- 범주 간 순서가 있는 경우: 타겟 인코딩은 타겟 변수와 범주형 변수 간의 관계를 수치적으로 표현하므로 더 의미 있는 정보를 제공할 수 있습니다.\n","- 타겟과 관련된 중요한 정보를 보존: 단순한 원-핫 인코딩이나 라벨 인코딩보다, 타겟과의 관계를 직접적으로 반영할 수 있습니다.\n","\n","- 타겟 인코딩의 동작 방식:\n","1. 범주형 변수를 기준으로 타겟의 평균을 계산: 예를 들어, 차량 A에 해당하는 고객들의 타겟 변수 평균을 계산합니다.\n","2. 스무딩(Smoothing) 적용: 샘플이 적은 범주는 계산된 평균이 불안정할 수 있기 때문에, 스무딩을 통해 샘플 수가 적은 범주는 전체 타겟 평균에 더 가깝게 조정합니다.\n","3. 노이즈 추가: 과적합을 방지하기 위해 노이즈를 추가하여, 모델이 학습 데이터에 지나치게 적합하지 않도록 합니다."],"metadata":{"id":"7qkOYL2plcI5"}},{"cell_type":"code","source":["# Funcitons from olivier's kernel\n","# https://www.kaggle.com/ogrellier/xgb-classifier-upsampling-lb-0-283\n","\n","def gini_xgb(preds, dtrain): # XGBoost에서 사용하기 위한 Gini 평가 지표\n","    labels = dtrain.get_label()\n","    gini_score = -eval_gini(labels, preds)\n","    return [('gini', gini_score)]\n","\n","\n","def add_noise(series, noise_level): # 노이즈를 추가하여 데이터의 변동성을 조절하는 함수입니다. 이는 타겟 인코딩에서 사용되며, 학습 과정에서 과적합을 방지하고 일반화 성능을 향상시키기 위해 사용됩니다.\n","    return series * (1 + noise_level * np.random.randn(len(series)))\n","\n","\n","# 타겟 인코딩(target encoding)**은 범주형 변수를 타겟 변수의 평균값으로 인코딩하는 기법입니다.\n","# 범주형 변수를 타겟과 연관된 수치형 변수로 변환하는 방법으로, 특히 높은 범주 개수를 가진 변수에서 유용합니다.\n","# 평활화(smoothing)**를 통해 카테고리 내 샘플 수가 적을 경우 전체 평균에 더 가깝게 계산되도록 하여, 과적합을 방지합니다.\n","\n","def target_encode(trn_series=None,    # Revised to encode validation series\n","                  val_series=None,\n","                  tst_series=None,\n","                  target=None,\n","                  min_samples_leaf=1,\n","                  smoothing=1,\n","                  noise_level=0):\n","    \"\"\"\n","    Smoothing is computed like in the following paper by Daniele Micci-Barreca\n","    https://kaggle2.blob.core.windows.net/forum-message-attachments/225952/7441/high%20cardinality%20categoricals.pdf\n","    trn_series : training categorical feature as a pd.Series\n","    tst_series : test categorical feature as a pd.Series\n","    target : target data as a pd.Series\n","    min_samples_leaf (int) : minimum samples to take category average into account\n","    smoothing (int) : smoothing effect to balance categorical average vs prior\n","    \"\"\"\n","    assert len(trn_series) == len(target)\n","    assert trn_series.name == tst_series.name\n","    temp = pd.concat([trn_series, target], axis=1)\n","    # Compute target mean\n","    averages = temp.groupby(by=trn_series.name)[target.name].agg([\"mean\", \"count\"])\n","    # Compute smoothing\n","    smoothing = 1 / (1 + np.exp(-(averages[\"count\"] - min_samples_leaf) / smoothing))\n","    # Apply average function to all target data\n","    prior = target.mean()\n","    # The bigger the count the less full_avg is taken into account\n","    averages[target.name] = prior * (1 - smoothing) + averages[\"mean\"] * smoothing\n","    averages.drop([\"mean\", \"count\"], axis=1, inplace=True)\n","    # Apply averages to trn and tst series\n","    ft_trn_series = pd.merge(\n","        trn_series.to_frame(trn_series.name),\n","        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n","        on=trn_series.name,\n","        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n","    # pd.merge does not keep the index so restore it\n","    ft_trn_series.index = trn_series.index\n","    ft_val_series = pd.merge(\n","        val_series.to_frame(val_series.name),\n","        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n","        on=val_series.name,\n","        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n","    # pd.merge does not keep the index so restore it\n","    ft_val_series.index = val_series.index\n","    ft_tst_series = pd.merge(\n","        tst_series.to_frame(tst_series.name),\n","        averages.reset_index().rename(columns={'index': target.name, target.name: 'average'}),\n","        on=tst_series.name,\n","        how='left')['average'].rename(trn_series.name + '_mean').fillna(prior)\n","    # pd.merge does not keep the index so restore it\n","    ft_tst_series.index = tst_series.index\n","    return add_noise(ft_trn_series, noise_level), add_noise(ft_val_series, noise_level), add_noise(ft_tst_series, noise_level)\n"],"metadata":{"id":"lAG7xvPPi84u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Read data\n","train_df = pd.read_csv('../input/train.csv', na_values=\"-1\") # .iloc[0:200,:]\n","test_df = pd.read_csv('../input/test.csv', na_values=\"-1\")"],"metadata":{"id":"pJcqAB4Oi_xm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# from olivier\n","train_features = [\n","    \"ps_car_13\",  #            : 1571.65 / shadow  609.23\n","\t\"ps_reg_03\",  #            : 1408.42 / shadow  511.15\n","\t\"ps_ind_05_cat\",  #        : 1387.87 / shadow   84.72\n","\t\"ps_ind_03\",  #            : 1219.47 / shadow  230.55\n","\t\"ps_ind_15\",  #            :  922.18 / shadow  242.00\n","\t\"ps_reg_02\",  #            :  920.65 / shadow  267.50\n","\t\"ps_car_14\",  #            :  798.48 / shadow  549.58\n","\t\"ps_car_12\",  #            :  731.93 / shadow  293.62\n","\t\"ps_car_01_cat\",  #        :  698.07 / shadow  178.72\n","\t\"ps_car_07_cat\",  #        :  694.53 / shadow   36.35\n","\t\"ps_ind_17_bin\",  #        :  620.77 / shadow   23.15\n","\t\"ps_car_03_cat\",  #        :  611.73 / shadow   50.67\n","\t\"ps_reg_01\",  #            :  598.60 / shadow  178.57\n","\t\"ps_car_15\",  #            :  593.35 / shadow  226.43\n","\t\"ps_ind_01\",  #            :  547.32 / shadow  154.58\n","\t\"ps_ind_16_bin\",  #        :  475.37 / shadow   34.17\n","\t\"ps_ind_07_bin\",  #        :  435.28 / shadow   28.92\n","\t\"ps_car_06_cat\",  #        :  398.02 / shadow  212.43\n","\t\"ps_car_04_cat\",  #        :  376.87 / shadow   76.98\n","\t\"ps_ind_06_bin\",  #        :  370.97 / shadow   36.13\n","\t\"ps_car_09_cat\",  #        :  214.12 / shadow   81.38\n","\t\"ps_car_02_cat\",  #        :  203.03 / shadow   26.67\n","\t\"ps_ind_02_cat\",  #        :  189.47 / shadow   65.68\n","\t\"ps_car_11\",  #            :  173.28 / shadow   76.45\n","\t\"ps_car_05_cat\",  #        :  172.75 / shadow   62.92\n","\t\"ps_calc_09\",  #           :  169.13 / shadow  129.72\n","\t\"ps_calc_05\",  #           :  148.83 / shadow  120.68\n","\t\"ps_ind_08_bin\",  #        :  140.73 / shadow   27.63\n","\t\"ps_car_08_cat\",  #        :  120.87 / shadow   28.82\n","\t\"ps_ind_09_bin\",  #        :  113.92 / shadow   27.05\n","\t\"ps_ind_04_cat\",  #        :  107.27 / shadow   37.43\n","\t\"ps_ind_18_bin\",  #        :   77.42 / shadow   25.97\n","\t\"ps_ind_12_bin\",  #        :   39.67 / shadow   15.52\n","\t\"ps_ind_14\",  #            :   37.37 / shadow   16.65\n","]\n","# add combinations\n","combs = [\n","    ('ps_reg_01', 'ps_car_02_cat'),\n","    ('ps_reg_01', 'ps_car_04_cat'),\n","]"],"metadata":{"id":"F-oFfCVujCVr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###[질문] 무슨 조합인거 ?\n","\n","상관관계 분석했을 떄 관계 있다고 나온 목록에 저 조합은 없음.\n","(ps_reg_01, ps_reg_03)\n","\n","(ps_reg_02, ps_reg_03)\n","\n","(ps_car_12, ps_car_13)\n","\n","(ps_car_13, ps_car_15)\n","\n","중요도가 높나?,,,"],"metadata":{"id":"i55LuZV43Tu4"}},{"cell_type":"markdown","source":["이 코드에서는 **특정 피처(features)**와 **피처의 조합(combinations)**을 정의하여 모델 학습에 활용할 준비를 하고 있습니다. 특히 Olivier의 커널에서 사용된 이 코드는 피처 중요도에 따라 선택된 피처들로 구성된 리스트와, 추가적인 피처 조합(두 개 이상의 피처를 결합한 새로운 피처)을 정의하고 있습니다."],"metadata":{"id":"N_GWbofvl9ah"}},{"cell_type":"code","source":["# Process data\n","id_test = test_df['id'].values\n","id_train = train_df['id'].values\n","y = train_df['target']\n","\n","start = time.time()\n","for n_c, (f1, f2) in enumerate(combs): # 피처 조합 및 라벨 인코딩:\n","    name1 = f1 + \"_plus_\" + f2 # 조합 피처 생성:\n","    print('current feature %60s %4d in %5.1f'\n","          % (name1, n_c + 1, (time.time() - start) / 60), end='')\n","    print('\\r' * 75, end='')\n","    train_df[name1] = train_df[f1].apply(lambda x: str(x)) + \"_\" + train_df[f2].apply(lambda x: str(x))\n","    test_df[name1] = test_df[f1].apply(lambda x: str(x)) + \"_\" + test_df[f2].apply(lambda x: str(x))\n","\n","    # Label Encode 라벨 인코딩(Label Encoding): 생성된 조합 피처는 범주형 변수이므로, 이를 모델에서 처리할 수 있는 수치형 값으로 변환해야 합니다.\n","    lbl = LabelEncoder()\n","    lbl.fit(list(train_df[name1].values) + list(test_df[name1].values))\n","    train_df[name1] = lbl.transform(list(train_df[name1].values))\n","    test_df[name1] = lbl.transform(list(test_df[name1].values))\n","\n","    train_features.append(name1) # 학습할 피처 리스트에 추가: 생성된 피처(name1)는 최종 학습 데이터에 추가\n","\n","X = train_df[train_features] #  최종 학습 데이터 준비:\n","test_df = test_df[train_features]\n","\n","f_cats = [f for f in X.columns if \"_cat\" in f] # 범주형 피처 식별:"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VquYSQeUjFL8","executionInfo":{"status":"ok","timestamp":1727089374566,"user_tz":-540,"elapsed":7168,"user":{"displayName":"Yeongeun Ra","userId":"17702977685342597921"}},"outputId":"8a548f12-836b-49d3-d8b5-8111f55d7e42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":[]}]},{"cell_type":"markdown","source":["f1과 f2라는 두 개의 피처를 문자열로 변환한 후 결합하여 새로운 피처를 만듭니다.\n","예를 들어, ps_reg_01이 1.2, ps_car_02_cat이 A인 경우, 조합된 피처 값은 **\"1.2_A\"**가 됩니다."],"metadata":{"id":"yvIP25Hz6jD8"}},{"cell_type":"markdown","source":["이 코드는 데이터 처리 단계에서 피처 조합을 생성하고, 생성된 피처들을 **라벨 인코딩(Label Encoding)**한 후, 학습에 사용할 최종 데이터셋을 만드는 과정입니다. 주로 범주형 피처들의 조합을 생성하고, 이를 모델이 처리할 수 있는 수치형 값으로 변환하는 것을 목표로 합니다."],"metadata":{"id":"Q3KOAvmRl-Q6"}},{"outputs":[],"cell_type":"code","metadata":{"_uuid":"6255e3c12616b0279cef5c1bdec97751bb72d8b8","collapsed":true,"_cell_guid":"1b36eb15-ee01-43a3-8766-27650f98158d","id":"94QUiPjUiOtZ"},"execution_count":null,"source":["y_valid_pred = 0*y\n","y_test_pred = 0"]},{"cell_type":"markdown","source":[" 코드에서 y_valid_pred와 y_test_pred는 초기화 작업을 의미합니다. 이 두 변수는 각각 검증 데이터셋과 테스트 데이터셋에서의 예측 값을 저장하기 위한 변수로 사용됩니다."],"metadata":{"id":"dGxSj5vhnEYL"}},{"outputs":[],"cell_type":"code","metadata":{"_uuid":"6aa7ada2193c2e4b8a63eebda925cee5023b45b0","collapsed":true,"_cell_guid":"7c6e4823-4e8c-4408-b961-576d469e9241","id":"3bU6R84YiOtZ"},"execution_count":null,"source":["# Set up folds\n","K = 5\n","kf = KFold(n_splits = K, random_state = 1, shuffle = True)\n","np.random.seed(0)"]},{"cell_type":"markdown","source":["K개의 폴드(fold)**로 나누고, 각 폴드를 한 번씩 검증 세트로 사용하면서 나머지 데이터를 훈련 세트로 사용하는 방식"],"metadata":{"id":"0s10v8ObnMX3"}},{"outputs":[],"cell_type":"code","metadata":{"_uuid":"581c3f15f294378a0e2ac3305e9e3d375f664b21","collapsed":true,"_cell_guid":"5d8108f3-e9e8-45d6-93b5-740eb7b4b10b","id":"_jB4MEjDiOtZ"},"execution_count":null,"source":["# Set up classifier\n","model = XGBClassifier(\n","                        n_estimators=MAX_ROUNDS,\n","                        max_depth=4,\n","                        objective=\"binary:logistic\",\n","                        learning_rate=LEARNING_RATE,\n","                        subsample=.8,\n","                        min_child_weight=6,\n","                        colsample_bytree=.8,\n","                        scale_pos_weight=1.6, # 불균형한 클래스에서 양성 클래스(1)의 가중치를 조정하는 파라미터입니다. #양성 클래스 1 가 더 작은 경우 양성을 더 중요하게 학습하도록\n","                        gamma=10,\n","                        reg_alpha=8,\n","                        reg_lambda=1.3,\n","                     )"]},{"cell_type":"markdown","source":["네, 맞습니다. **scale_pos_weight=1.6**을 설정한 것은 타겟 변수의 불균형을 처리하기 위해 XGBoost에서 제공하는 파라미터를 활용한 것입니다. 즉, 별도로 언더샘플링(undersampling), **오버샘플링(oversampling)**과 같은 데이터 전처리를 하지 않고, XGBoost의 내부 파라미터를 통해 불균형 문제를 해결하려는 접근입니다.\n","\n","**scale_pos_weight**에 대한 설명:\n","**scale_pos_weight**는 클래스 불균형 문제를 해결하기 위해, **양성 클래스(1)**의 가중치를 조정하는 파라미터입니다."],"metadata":{"id":"GHzMU5SxvhEe"}},{"cell_type":"markdown","source":["다양한 하이퍼파라미터를 사용해 XGBoost 모델을 최적화하려는 목적을 가지고 있습니다. XGBoost는 트리 기반의 앙상블 학습 알고리즘으로, 특히 **부스팅(Boosting)**을 통해 고성능을 달성할 수 있는 모델입니다. 여기서는 이진 분류 문제를 해결하기 위한 XGBClassifier가 설정되어 있습니다."],"metadata":{"id":"JA2szIkHnXeB"}},{"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Fold  0\n"]},{"output_type":"error","ename":"TypingError","evalue":"Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at <ipython-input-4-491d77ce49f3> (4)\n\nFile \"<ipython-input-4-491d77ce49f3>\", line 4:\n# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n@jit\n^ \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'pandas.core.series.Series'>\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-30379ce8fa3e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m# Generate validation predictions for this fold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"  Gini = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_gini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0my_valid_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_index\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at <ipython-input-4-491d77ce49f3> (4)\n\nFile \"<ipython-input-4-491d77ce49f3>\", line 4:\n# from CPMP's kernel https://www.kaggle.com/cpmpml/extremely-fast-gini-computation\n@jit\n^ \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'pandas.core.series.Series'>\n"]}],"cell_type":"code","metadata":{"_uuid":"2b9ed96c98b705d3e4bf2a3d60323dfab4332674","scrolled":true,"collapsed":true,"_cell_guid":"c4e48347-920f-4ba7-8b37-cfbaab4c3c00","id":"OqYZ_Mz-iOtZ","colab":{"base_uri":"https://localhost:8080/","height":586},"executionInfo":{"status":"error","timestamp":1727090375596,"user_tz":-540,"elapsed":27710,"user":{"displayName":"Yeongeun Ra","userId":"17702977685342597921"}},"outputId":"3ae274e0-3502-441b-c7ce-121a128ec0a0"},"execution_count":null,"source":["# Run CV\n","\n","for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n","\n","    # Create data for this fold\n","    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n","    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n","    X_test = test_df.copy()\n","    print( \"\\nFold \", i)\n","\n","    # Enocode data\n","    for f in f_cats:\n","        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n","                                                        trn_series=X_train[f],\n","                                                        val_series=X_valid[f],\n","                                                        tst_series=X_test[f],\n","                                                        target=y_train,\n","                                                        min_samples_leaf=200,\n","                                                        smoothing=10,\n","                                                        noise_level=0\n","                                                        )\n","    # Run model for this fold\n","    if OPTIMIZE_ROUNDS:\n","        eval_set=[(X_valid,y_valid)]\n","        fit_model = model.fit( X_train, y_train,\n","                               eval_set=eval_set,\n","                               eval_metric=gini_xgb,\n","                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n","                               verbose=False\n","                             )\n","        print( \"  Best N trees = \", model.best_ntree_limit )\n","        print( \"  Best gini = \", model.best_score )\n","    else:\n","        fit_model = model.fit( X_train, y_train )\n","\n","    # Generate validation predictions for this fold\n","    pred = fit_model.predict_proba(X_valid)[:,1]\n","    print( \"  Gini = \", eval_gini(y_valid, pred) )\n","    y_valid_pred.iloc[test_index] = pred\n","\n","    # Accumulate test set predictions\n","    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n","\n","    del X_test, X_train, X_valid, y_train\n","\n","y_test_pred /= K  # Average test set predictions\n","\n","print( \"\\nGini for full training set:\" )\n","eval_gini(y, y_valid_pred)"]},{"cell_type":"markdown","source":["andas Series와 Numba의 호환성 문제에서 발생한 것으로, Numba는 정적 타입을 사용해야 하기 때문에 NumPy 배열로 변환하여 해결했습니다. eval_gini 함수의 입력을 NumPy 배열로 변환하면 Numba가 효율적으로 실행될 수 있습니다."],"metadata":{"id":"oBGQb3JNp8ya"}},{"cell_type":"code","source":["# Run CV\n","\n","for i, (train_index, test_index) in enumerate(kf.split(train_df)):\n","\n","    # Create data for this fold\n","    y_train, y_valid = y.iloc[train_index].copy(), y.iloc[test_index]\n","    X_train, X_valid = X.iloc[train_index,:].copy(), X.iloc[test_index,:].copy()\n","    X_test = test_df.copy()\n","    print( \"\\nFold \", i)\n","\n","    # Enocode data\n","    for f in f_cats:\n","        X_train[f + \"_avg\"], X_valid[f + \"_avg\"], X_test[f + \"_avg\"] = target_encode(\n","                                                        trn_series=X_train[f],\n","                                                        val_series=X_valid[f],\n","                                                        tst_series=X_test[f],\n","                                                        target=y_train,\n","                                                        min_samples_leaf=200,\n","                                                        smoothing=10,\n","                                                        noise_level=0\n","                                                        )\n","    # Run model for this fold\n","    if OPTIMIZE_ROUNDS:\n","        eval_set=[(X_valid,y_valid)]\n","        fit_model = model.fit( X_train, y_train,\n","                               eval_set=eval_set,\n","                               eval_metric=gini_xgb,\n","                               early_stopping_rounds=EARLY_STOPPING_ROUNDS,\n","                               verbose=False\n","                             )\n","        print( \"  Best N trees = \", model.best_ntree_limit )\n","        print( \"  Best gini = \", model.best_score )\n","    else:\n","        fit_model = model.fit( X_train, y_train )\n","\n","    # Generate validation predictions for this fold\n","    pred = fit_model.predict_proba(X_valid)[:,1]\n","    print(\"  Gini = \", eval_gini(y_valid.values, pred))  # NumPy 배열로 변환\n","    y_valid_pred.iloc[test_index] = pred\n","\n","    # Accumulate test set predictions\n","    y_test_pred += fit_model.predict_proba(X_test)[:,1]\n","\n","    del X_test, X_train, X_valid, y_train\n","\n","y_test_pred /= K  # Average test set predictions\n","\n","print( \"\\nGini for full training set:\" )\n","eval_gini(y, y_valid_pred)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":896},"id":"W9QxyGJTpasX","executionInfo":{"status":"error","timestamp":1727091223939,"user_tz":-540,"elapsed":155917,"user":{"displayName":"Yeongeun Ra","userId":"17702977685342597921"}},"outputId":"e3d9b2cf-4605-430f-8408-33b1851fb7df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Fold  0\n","  Gini =  0.2835949122243291\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-15-d8eb241e7ab5>:39: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.02633461 0.04840057 0.07342175 ... 0.03756154 0.03881263 0.05186315]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  y_valid_pred.iloc[test_index] = pred\n"]},{"output_type":"stream","name":"stdout","text":["\n","Fold  1\n","  Gini =  0.27560303878224934\n","\n","Fold  2\n","  Gini =  0.27029621161626916\n","\n","Fold  3\n","  Gini =  0.2955171592640802\n","\n","Fold  4\n","  Gini =  0.28002481212908004\n","\n","Gini for full training set:\n"]},{"output_type":"error","ename":"TypingError","evalue":"Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at <ipython-input-14-8a4c37fc4fd5> (4)\n\nFile \"<ipython-input-14-8a4c37fc4fd5>\", line 4:\n\n@jit\n^ \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'pandas.core.series.Series'>\n- argument 1: Cannot determine Numba type of <class 'pandas.core.series.Series'>\n","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypingError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-d8eb241e7ab5>\u001b[0m in \u001b[0;36m<cell line: 49>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"\\nGini for full training set:\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0meval_gini\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36m_compile_for_args\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m             \u001b[0merror_rewrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'typing'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnsupportedError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0;31m# Something unsupported is present in the user code, add help info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numba/core/dispatcher.py\u001b[0m in \u001b[0;36merror_rewrite\u001b[0;34m(e, issue_type)\u001b[0m\n\u001b[1;32m    362\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0margtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypingError\u001b[0m: Failed in nopython mode pipeline (step: nopython frontend)\nnon-precise type pyobject\nDuring: typing of argument at <ipython-input-14-8a4c37fc4fd5> (4)\n\nFile \"<ipython-input-14-8a4c37fc4fd5>\", line 4:\n\n@jit\n^ \n\nThis error may have been caused by the following argument(s):\n- argument 0: Cannot determine Numba type of <class 'pandas.core.series.Series'>\n- argument 1: Cannot determine Numba type of <class 'pandas.core.series.Series'>\n"]}]},{"cell_type":"markdown","source":["설명:\n","- 각 폴드별 Gini 점수:\n","\n","Fold 0부터 Fold 4까지 총 5개의 폴드에서 계산된 Gini 점수를 확인할 수 있습니다.\n","각 폴드에서 검증 데이터에 대한 예측 결과를 Gini 계수로 평가하여 출력하였습니다.\n","\n","---\n","\n","\n","\n","---\n","\n","\n","0일수록 좋다\n","- 전체 학습 세트에 대한 Gini 점수:\n","\n","마지막 줄의 Gini for full training set은 전체 학습 세트에 대한 Gini 계수로, 5개의 폴드에서 얻은 검증 결과를 종합한 후 계산한 Gini 점수입니다.\n","최종적으로 0.2869로 평가되었으며, 이는 모델이 학습 데이터에 대해 중간 정도의 예측 성능을 보여준다는 것을 나타냅니다."],"metadata":{"id":"7K3WnW-Aqg5V"}},{"cell_type":"markdown","source":["AUC 0.64에 해당합니다. 이는 모델이 **랜덤 예측(AUC=0.5)**보다는 약간 더 나은 성능을 보여주지만,"],"metadata":{"id":"XA3Ye8SQqoQ7"}},{"cell_type":"code","source":["## 지니 계수 ?"],"metadata":{"id":"x5RfkgA5BPRb"},"execution_count":null,"outputs":[]},{"outputs":[],"cell_type":"code","metadata":{"_uuid":"e61bf4e22c1c29c8358caeecb6e67d6658f2005d","collapsed":true,"_cell_guid":"0e3dfd76-c566-4b8d-a460-b56e964d0772","id":"UM-jydkAiOta"},"execution_count":null,"source":["# Save validation predictions for stacking/ensembling 검증데이터 예측 결과 저장\n","val = pd.DataFrame()\n","val['id'] = id_train\n","val['target'] = y_valid_pred.values\n","val.to_csv('xgb_valid.csv', float_format='%.6f', index=False)"]},{"outputs":[],"cell_type":"code","metadata":{"_uuid":"380fc8053d00cd8bb2796bfd2b59d10cbc4ce7e1","collapsed":true,"_cell_guid":"f4cbef2c-e52b-4afb-b8ef-904ee9b5f9d5","id":"_oHru-BfiOta"},"execution_count":null,"source":["# Create submission file #테스터 데이터 예측 결과 저장\n","sub = pd.DataFrame()\n","sub['id'] = id_test\n","sub['target'] = y_test_pred\n","sub.to_csv('xgb_submit.csv', float_format='%.6f', index=False)"]},{"cell_type":"markdown","metadata":{"_uuid":"5401495c2c34ef736c761573c70d7e3b4efa3a5b","_cell_guid":"77516718-78a9-4043-8b4b-0b04276e4345","id":"nR9Kc4LKiOta"},"source":["Notes:<br>\n","version 16. Baseline best CV=.2832, LB=.282<br>\n","version 15. Ntree optimization for baseline<br>\n","version 21. Verbose version of baseline optimization<br>\n","version 22. Baseline + per-fold early stopping after 20 rounds<br>\n","version 23. Back to baseline.<br>\n","version 24. Some parameter tuning.<br>\n","version 25. Re-published to make it visible.<br>\n","version 26. A little more tuning.<br>\n","version 27: More tuning, get rid of upsampling (using  **<code>scale_pos_weight</code>** instead),<br>\n","                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","                    &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n","                    Set <code>OPTIMIZE_ROUNDS</code> and <code>verbose</code> temporarily<br>\n","version 28: <code>MAX_ROUNDS=300</code> as a compromise<br>\n","version 29: Substantively identical. (Turn off now-irrelevant <code>verbose</code>.)<br>\n","version 30: Still substantively identical. Some visual cleanup.<br>\n","version 35. More tuning. CV went up but LB sorts lower (still .283)<br>\n","version 36. Identical (except turn off irrelevant <code>verbose</code>). Republished to make it visible.<br>\n","versions 37-42. More tuning (gamma=10, alpha=8). LB .284 (\\*end zone dance\\*).<br>\n","version 43. More tuning (min_child_weight=6).  LB score has considerably improved according to sort, but still .284"]},{"outputs":[],"cell_type":"code","metadata":{"collapsed":true,"id":"Ih4GEdR0iOta"},"execution_count":null,"source":["## 타겟 변수 불균형 문제 ~ 따로 전처리하지 않고 xgboost 모델로 해결?\n","##"]}]}